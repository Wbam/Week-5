{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to load CoNLL data\n",
    "def load_conll_data(file_path):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        sentence = []\n",
    "        label = []\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line:  \n",
    "                token, tag = line.split()\n",
    "                sentence.append(token)\n",
    "                label.append(tag)\n",
    "            else:  \n",
    "                sentences.append(sentence)\n",
    "                labels.append(label)\n",
    "                sentence = []\n",
    "                label = []\n",
    "    return sentences, labels\n",
    "\n",
    "sentences, labels = load_conll_data('labeled_dataset.conll')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLMRobertaTokenizer\n",
    "\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "\n",
    "tokenized_inputs = []\n",
    "label_list = []\n",
    "\n",
    "for sentence, label in zip(sentences, labels):\n",
    "    \n",
    "    encoding = tokenizer(sentence, is_split_into_words=True, padding='max_length', truncation=True, return_tensors=\"pt\", max_length=128)\n",
    "    tokenized_inputs.append(encoding)\n",
    "\n",
    "    aligned_labels = []\n",
    "   \n",
    "    label_index = 0\n",
    "\n",
    "    for token_id in encoding['input_ids'][0]:\n",
    "        \n",
    "        token = tokenizer.convert_ids_to_tokens(token_id.item())\n",
    "        if token.startswith('‚ñÅ'):  \n",
    "            token = token[1:]  \n",
    "        \n",
    "        if label_index < len(label) and sentence[label_index] == token:\n",
    "            aligned_labels.append(label[label_index])\n",
    "            label_index += 1\n",
    "        else:\n",
    "            aligned_labels.append(\"O\")  \n",
    "\n",
    "    # Pad the labels to match the tokenized length\n",
    "    aligned_labels = aligned_labels + ['O'] * (encoding['input_ids'].shape[1] - len(aligned_labels))\n",
    "    label_list.append(aligned_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLMRobertaForTokenClassification, Trainer, DataCollatorForTokenClassification\n",
    "\n",
    "\n",
    "labels = [\n",
    "    [\"B-Product\", \"O\", \"B-LOC\", \"O\"],\n",
    "    [\"O\", \"B-PRICE\", \"O\", \"O\", \"B-PRICE\"],\n",
    "    \n",
    "]\n",
    "\n",
    "all_labels = [label for sublist in labels for label in sublist]  \n",
    "unique_labels = list(set(all_labels))  \n",
    "\n",
    "model = XLMRobertaForTokenClassification.from_pretrained(\"xlm-roberta-base\", num_labels=len(unique_labels))\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,  \n",
    "    eval_dataset=eval_dataset,     \n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
